{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment-CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoheikikuta/DeepGamblers-tensorflow/blob/master/colab/experiment_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTJvr5OlpKeM",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- Set up to connect to Google Drive\n",
        "- Tensorflow preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV6JNEhkd-6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUoUskE8eN9t",
        "colab_type": "code",
        "outputId": "ac2bee51-cd9c-4a66-b094-6c0d27a8c45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google import colab\n",
        "colab.drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZbkbuqfqVgv",
        "colab_type": "code",
        "outputId": "d24319ba-f61b-452d-87b4-9a841210cf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rsmoa-hruzq",
        "colab_type": "code",
        "outputId": "d9f1f408-82f1-4edf-b7ae-348beb3e78b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU5UBpPp4e5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from absl import app, flags, logging\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-YPjCcKpUiy",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF26v0CI4fCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGGBlock(layers.Layer):\n",
        "    \"\"\"VGG model building block\n",
        "    if last_layer of the block:\n",
        "        conv -> relu -> batchnorm -> pooling\n",
        "    else:\n",
        "        conv -> relu -> batchnorm -> dropout\n",
        "    \"\"\"\n",
        "    def __init__(self, name=None, num_filter=32,\n",
        "                 dropout_rate=0.3, is_last=False, **kwargs):\n",
        "        super(VGGBlock, self).__init__(name=name, **kwargs)\n",
        "        self.conv = layers.Conv2D(filters=num_filter, kernel_size=3, padding=\"same\",\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(5e-4))\n",
        "        self.relu = layers.ReLU()\n",
        "        self.batchnorm = layers.BatchNormalization(epsilon=1e-5)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.pooling = layers.MaxPool2D(pool_size=(2, 2))\n",
        "        self.is_last = is_last\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.conv(inputs)\n",
        "        x = self.relu(x)\n",
        "        x = self.batchnorm(x, training)\n",
        "        if self.is_last:\n",
        "            x = self.pooling(x)\n",
        "        else:\n",
        "            x = self.dropout(x, training)\n",
        "        return x\n",
        "\n",
        "\n",
        "class VGGBuilder(tf.keras.Model):\n",
        "    \"\"\"VGG model builder\"\"\"\n",
        "    def __init__(self, name=\"vgg16\", **kwargs):\n",
        "        super(VGGBuilder, self).__init__(name=name, **kwargs)\n",
        "        if name == \"vgg16\":\n",
        "            # block num, filter num, dropout rate\n",
        "            self.structures = {\"stage1\": [2, 64, 0.3],\n",
        "                               \"stage2\": [2, 128, 0.4],\n",
        "                               \"stage3\": [3, 256, 0.4],\n",
        "                               \"stage4\": [3, 512, 0.4],\n",
        "                               \"stage5\": [3, 512, 0.4]}\n",
        "            self.blocks = []\n",
        "            for key in self.structures:\n",
        "                num_block, num_filter, dropout_rate = self.structures[key]\n",
        "                for idx, block in enumerate(range(num_block), start=1):\n",
        "                    is_last = (num_block == idx)\n",
        "                    self.blocks.append(VGGBlock(f\"{key}_{idx}\", num_filter,\n",
        "                                                dropout_rate, is_last))\n",
        "        self.dropout = layers.Dropout(0.5)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense = layers.Dense(512,\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(5e-4))\n",
        "        self.relu = layers.ReLU()\n",
        "        self.batchnorm = layers.BatchNormalization(epsilon=1e-5)\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = inputs\n",
        "        for layer in self.blocks:\n",
        "            x = layer(x, training)\n",
        "        x = self.dropout(x, training)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.batchnorm(x, training)\n",
        "        return x\n",
        "\n",
        "\n",
        "class VGGClassifier(tf.keras.Model):\n",
        "    \"\"\"Classifier that outputs softmax probabilities\"\"\"\n",
        "    def __init__(self, name=\"vgg16_classifier\",\n",
        "                 input_shapes=(32, 32, 3), num_classes=10, **kwargs):\n",
        "        super(VGGClassifier, self).__init__(name=name, **kwargs)\n",
        "        self.input_layer = layers.InputLayer(input_shape=input_shapes)\n",
        "        self.vgg = VGGBuilder()\n",
        "        self.dropout = layers.Dropout(0.5)\n",
        "        self.dense = layers.Dense(num_classes,\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(5e-4))\n",
        "        self.softmax = layers.Softmax()\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.input_layer(inputs)\n",
        "        x = self.vgg(x, training)\n",
        "        x = self.dropout(x, training)\n",
        "        x = self.dense(x)\n",
        "        # x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr2L2b5B4fHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gambler loss that proposed in the paper\n",
        "def gambler_loss(model, x, y, o):\n",
        "    # \\sum_{i=1}^{m} y_i log(p_i + (1 / o) p_{m+1})\n",
        "    EPS = 1e-5\n",
        "    logit = model(x)\n",
        "    prob = tf.nn.softmax(logit)\n",
        "    prob = tf.clip_by_value(prob, EPS, 1.0 - EPS)\n",
        "    class_pred, abstention = tf.split(prob, [prob.shape[1] - 1, 1], 1)\n",
        "    abstention /= o\n",
        "    weighted_prob = tf.concat([class_pred, abstention], 1)\n",
        "\n",
        "    label_shape = y.shape\n",
        "    extended_label = tf.concat([y, tf.constant(1.0, shape=[label_shape[0], 1])], 1)\n",
        "\n",
        "    log_arg = tf.reduce_sum(extended_label * weighted_prob, 1)\n",
        "    loss = -tf.reduce_mean(tf.math.log(log_arg))\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cross_entropy_loss(model, x, y):\n",
        "    logit = model(x)\n",
        "    class_logit, abstention = tf.split(logit, [logit.shape[1] - 1, 1], 1)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=class_logit))\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train(model, optimizer, trainset, o, epoch, pretrain_num):\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(trainset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            if epoch <= pretrain_num:\n",
        "                loss = cross_entropy_loss(model, x_batch_train, y_batch_train)\n",
        "            else:\n",
        "                loss = gambler_loss(model, x_batch_train, y_batch_train, o)\n",
        "            # print(loss)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "\n",
        "def evaluate(model, testset):\n",
        "    training = False\n",
        "    predictions = np.array([], dtype=np.float32).reshape(0, 11)\n",
        "    answers = np.array([], dtype=np.int8).reshape(0)\n",
        "    for (x_batch_test, y_batch_test) in testset:\n",
        "        preds = model(x_batch_test, training)\n",
        "        predictions = np.vstack([predictions, preds.numpy()])\n",
        "        answers = np.hstack([answers, y_batch_test.numpy().flatten()])\n",
        "\n",
        "    return predictions, answers\n",
        "\n",
        "\n",
        "def data_augmentation(x):\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "    x = tf.pad(x, tf.constant([[2, 2], [2, 2], [0, 0]]), \"REFLECT\")\n",
        "    x = tf.image.random_crop(x, size=[32, 32, 3])\n",
        "    return x\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    MEAN = tf.constant([0.4914, 0.4822, 0.4465], dtype=tf.float32)\n",
        "    STD = tf.constant([0.2023, 0.1994, 0.2010], dtype=tf.float32)\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    trainset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    trainset = trainset.map(\n",
        "        lambda image, label: (\n",
        "            data_augmentation((tf.cast(image, tf.float32) / 255.0) - MEAN / STD),\n",
        "            tf.squeeze(tf.cast(tf.one_hot(label, depth=10), tf.float32)))\n",
        "    ).shuffle(buffer_size=1024).batch(128)\n",
        "\n",
        "    testset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    testset = testset.map(\n",
        "        lambda image, label: (\n",
        "            (tf.cast(image, tf.float32) / 255.0) - MEAN / STD,\n",
        "            label)\n",
        "    ).batch(128)\n",
        "\n",
        "    return trainset, testset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM2FKpOipXq0",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shVgJ0uqowQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DRIVE_DIR = \"gdrive/My Drive/DeepGamblers/\"\n",
        "\n",
        "if not os.path.exists(DRIVE_DIR):\n",
        "    os.makedirs(DRIVE_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9cakWrw4fMG",
        "colab_type": "code",
        "outputId": "2dd89dd6-de4f-4cef-f2dc-42223919f60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainset, testset = load_dataset()\n",
        "vgg16 = VGGClassifier(num_classes=10 + 1)  # +1 is for abstention class\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9)\n",
        "decay_rate = 0.5\n",
        "root = tf.train.Checkpoint(optimizer=optimizer, model=vgg16)\n",
        "\n",
        "for epoch in range(300):\n",
        "    print(f\"Start of epoch {epoch + 1}\")\n",
        "    if (epoch + 1) in [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275]:\n",
        "        optimizer.lr = optimizer.lr * decay_rate\n",
        "    train(vgg16, optimizer, trainset, o=2.2, epoch = epoch + 1, pretrain_num = 100)\n",
        "    if (epoch + 1) % 25 == 0:\n",
        "        root.save(os.path.join(DRIVE_DIR, \"ckpt\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 1\n",
            "Start of epoch 2\n",
            "Start of epoch 3\n",
            "Start of epoch 4\n",
            "Start of epoch 5\n",
            "Start of epoch 6\n",
            "Start of epoch 7\n",
            "Start of epoch 8\n",
            "Start of epoch 9\n",
            "Start of epoch 10\n",
            "Start of epoch 11\n",
            "Start of epoch 12\n",
            "Start of epoch 13\n",
            "Start of epoch 14\n",
            "Start of epoch 15\n",
            "Start of epoch 16\n",
            "Start of epoch 17\n",
            "Start of epoch 18\n",
            "Start of epoch 19\n",
            "Start of epoch 20\n",
            "Start of epoch 21\n",
            "Start of epoch 22\n",
            "Start of epoch 23\n",
            "Start of epoch 24\n",
            "Start of epoch 25\n",
            "Start of epoch 26\n",
            "Start of epoch 27\n",
            "Start of epoch 28\n",
            "Start of epoch 29\n",
            "Start of epoch 30\n",
            "Start of epoch 31\n",
            "Start of epoch 32\n",
            "Start of epoch 33\n",
            "Start of epoch 34\n",
            "Start of epoch 35\n",
            "Start of epoch 36\n",
            "Start of epoch 37\n",
            "Start of epoch 38\n",
            "Start of epoch 39\n",
            "Start of epoch 40\n",
            "Start of epoch 41\n",
            "Start of epoch 42\n",
            "Start of epoch 43\n",
            "Start of epoch 44\n",
            "Start of epoch 45\n",
            "Start of epoch 46\n",
            "Start of epoch 47\n",
            "Start of epoch 48\n",
            "Start of epoch 49\n",
            "Start of epoch 50\n",
            "Start of epoch 51\n",
            "Start of epoch 52\n",
            "Start of epoch 53\n",
            "Start of epoch 54\n",
            "Start of epoch 55\n",
            "Start of epoch 56\n",
            "Start of epoch 57\n",
            "Start of epoch 58\n",
            "Start of epoch 59\n",
            "Start of epoch 60\n",
            "Start of epoch 61\n",
            "Start of epoch 62\n",
            "Start of epoch 63\n",
            "Start of epoch 64\n",
            "Start of epoch 65\n",
            "Start of epoch 66\n",
            "Start of epoch 67\n",
            "Start of epoch 68\n",
            "Start of epoch 69\n",
            "Start of epoch 70\n",
            "Start of epoch 71\n",
            "Start of epoch 72\n",
            "Start of epoch 73\n",
            "Start of epoch 74\n",
            "Start of epoch 75\n",
            "Start of epoch 76\n",
            "Start of epoch 77\n",
            "Start of epoch 78\n",
            "Start of epoch 79\n",
            "Start of epoch 80\n",
            "Start of epoch 81\n",
            "Start of epoch 82\n",
            "Start of epoch 83\n",
            "Start of epoch 84\n",
            "Start of epoch 85\n",
            "Start of epoch 86\n",
            "Start of epoch 87\n",
            "Start of epoch 88\n",
            "Start of epoch 89\n",
            "Start of epoch 90\n",
            "Start of epoch 91\n",
            "Start of epoch 92\n",
            "Start of epoch 93\n",
            "Start of epoch 94\n",
            "Start of epoch 95\n",
            "Start of epoch 96\n",
            "Start of epoch 97\n",
            "Start of epoch 98\n",
            "Start of epoch 99\n",
            "Start of epoch 100\n",
            "Start of epoch 101\n",
            "Start of epoch 102\n",
            "Start of epoch 103\n",
            "Start of epoch 104\n",
            "Start of epoch 105\n",
            "Start of epoch 106\n",
            "Start of epoch 107\n",
            "Start of epoch 108\n",
            "Start of epoch 109\n",
            "Start of epoch 110\n",
            "Start of epoch 111\n",
            "Start of epoch 112\n",
            "Start of epoch 113\n",
            "Start of epoch 114\n",
            "Start of epoch 115\n",
            "Start of epoch 116\n",
            "Start of epoch 117\n",
            "Start of epoch 118\n",
            "Start of epoch 119\n",
            "Start of epoch 120\n",
            "Start of epoch 121\n",
            "Start of epoch 122\n",
            "Start of epoch 123\n",
            "Start of epoch 124\n",
            "Start of epoch 125\n",
            "Start of epoch 126\n",
            "Start of epoch 127\n",
            "Start of epoch 128\n",
            "Start of epoch 129\n",
            "Start of epoch 130\n",
            "Start of epoch 131\n",
            "Start of epoch 132\n",
            "Start of epoch 133\n",
            "Start of epoch 134\n",
            "Start of epoch 135\n",
            "Start of epoch 136\n",
            "Start of epoch 137\n",
            "Start of epoch 138\n",
            "Start of epoch 139\n",
            "Start of epoch 140\n",
            "Start of epoch 141\n",
            "Start of epoch 142\n",
            "Start of epoch 143\n",
            "Start of epoch 144\n",
            "Start of epoch 145\n",
            "Start of epoch 146\n",
            "Start of epoch 147\n",
            "Start of epoch 148\n",
            "Start of epoch 149\n",
            "Start of epoch 150\n",
            "Start of epoch 151\n",
            "Start of epoch 152\n",
            "Start of epoch 153\n",
            "Start of epoch 154\n",
            "Start of epoch 155\n",
            "Start of epoch 156\n",
            "Start of epoch 157\n",
            "Start of epoch 158\n",
            "Start of epoch 159\n",
            "Start of epoch 160\n",
            "Start of epoch 161\n",
            "Start of epoch 162\n",
            "Start of epoch 163\n",
            "Start of epoch 164\n",
            "Start of epoch 165\n",
            "Start of epoch 166\n",
            "Start of epoch 167\n",
            "Start of epoch 168\n",
            "Start of epoch 169\n",
            "Start of epoch 170\n",
            "Start of epoch 171\n",
            "Start of epoch 172\n",
            "Start of epoch 173\n",
            "Start of epoch 174\n",
            "Start of epoch 175\n",
            "Start of epoch 176\n",
            "Start of epoch 177\n",
            "Start of epoch 178\n",
            "Start of epoch 179\n",
            "Start of epoch 180\n",
            "Start of epoch 181\n",
            "Start of epoch 182\n",
            "Start of epoch 183\n",
            "Start of epoch 184\n",
            "Start of epoch 185\n",
            "Start of epoch 186\n",
            "Start of epoch 187\n",
            "Start of epoch 188\n",
            "Start of epoch 189\n",
            "Start of epoch 190\n",
            "Start of epoch 191\n",
            "Start of epoch 192\n",
            "Start of epoch 193\n",
            "Start of epoch 194\n",
            "Start of epoch 195\n",
            "Start of epoch 196\n",
            "Start of epoch 197\n",
            "Start of epoch 198\n",
            "Start of epoch 199\n",
            "Start of epoch 200\n",
            "Start of epoch 201\n",
            "Start of epoch 202\n",
            "Start of epoch 203\n",
            "Start of epoch 204\n",
            "Start of epoch 205\n",
            "Start of epoch 206\n",
            "Start of epoch 207\n",
            "Start of epoch 208\n",
            "Start of epoch 209\n",
            "Start of epoch 210\n",
            "Start of epoch 211\n",
            "Start of epoch 212\n",
            "Start of epoch 213\n",
            "Start of epoch 214\n",
            "Start of epoch 215\n",
            "Start of epoch 216\n",
            "Start of epoch 217\n",
            "Start of epoch 218\n",
            "Start of epoch 219\n",
            "Start of epoch 220\n",
            "Start of epoch 221\n",
            "Start of epoch 222\n",
            "Start of epoch 223\n",
            "Start of epoch 224\n",
            "Start of epoch 225\n",
            "Start of epoch 226\n",
            "Start of epoch 227\n",
            "Start of epoch 228\n",
            "Start of epoch 229\n",
            "Start of epoch 230\n",
            "Start of epoch 231\n",
            "Start of epoch 232\n",
            "Start of epoch 233\n",
            "Start of epoch 234\n",
            "Start of epoch 235\n",
            "Start of epoch 236\n",
            "Start of epoch 237\n",
            "Start of epoch 238\n",
            "Start of epoch 239\n",
            "Start of epoch 240\n",
            "Start of epoch 241\n",
            "Start of epoch 242\n",
            "Start of epoch 243\n",
            "Start of epoch 244\n",
            "Start of epoch 245\n",
            "Start of epoch 246\n",
            "Start of epoch 247\n",
            "Start of epoch 248\n",
            "Start of epoch 249\n",
            "Start of epoch 250\n",
            "Start of epoch 251\n",
            "Start of epoch 252\n",
            "Start of epoch 253\n",
            "Start of epoch 254\n",
            "Start of epoch 255\n",
            "Start of epoch 256\n",
            "Start of epoch 257\n",
            "Start of epoch 258\n",
            "Start of epoch 259\n",
            "Start of epoch 260\n",
            "Start of epoch 261\n",
            "Start of epoch 262\n",
            "Start of epoch 263\n",
            "Start of epoch 264\n",
            "Start of epoch 265\n",
            "Start of epoch 266\n",
            "Start of epoch 267\n",
            "Start of epoch 268\n",
            "Start of epoch 269\n",
            "Start of epoch 270\n",
            "Start of epoch 271\n",
            "Start of epoch 272\n",
            "Start of epoch 273\n",
            "Start of epoch 274\n",
            "Start of epoch 275\n",
            "Start of epoch 276\n",
            "Start of epoch 277\n",
            "Start of epoch 278\n",
            "Start of epoch 279\n",
            "Start of epoch 280\n",
            "Start of epoch 281\n",
            "Start of epoch 282\n",
            "Start of epoch 283\n",
            "Start of epoch 284\n",
            "Start of epoch 285\n",
            "Start of epoch 286\n",
            "Start of epoch 287\n",
            "Start of epoch 288\n",
            "Start of epoch 289\n",
            "Start of epoch 290\n",
            "Start of epoch 291\n",
            "Start of epoch 292\n",
            "Start of epoch 293\n",
            "Start of epoch 294\n",
            "Start of epoch 295\n",
            "Start of epoch 296\n",
            "Start of epoch 297\n",
            "Start of epoch 298\n",
            "Start of epoch 299\n",
            "Start of epoch 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XIJ6qoMDMJf",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XipFbYF0DONr",
        "colab_type": "code",
        "outputId": "abe9fb4a-a2de-46e5-888b-3ca37d19b00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "CKPT_PATH = \"gdrive/My Drive/DeepGamblers/ckpt-12\"\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9)\n",
        "vgg16 = VGGClassifier(num_classes=10 + 1)  # +1 is for abstention class\n",
        "\n",
        "ckpt = tf.train.Checkpoint(optimizer=optimizer, model=vgg16)\n",
        "ckpt.restore(CKPT_PATH)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcd0135d588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OflBuJT74fUB",
        "colab_type": "code",
        "outputId": "44c674da-2a30-49c3-e5d7-ae92997d47cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "trainset, testset = load_dataset()\n",
        "\n",
        "predictions, answers = evaluate(ckpt.model, testset)\n",
        "print(sum([np.argmax(elem) for elem in predictions] == answers))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "8415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyi8rhN94fXR",
        "colab_type": "code",
        "outputId": "06b27968-bc29-47b5-fcbf-9b281b625ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbp4HOrE4fGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = tf.nn.softmax(predictions).numpy()\n",
        "result = np.hstack([probs, answers.reshape(len(probs), 1)])\n",
        "result = result[result[:,-2].argsort()]  # Sort by abstention score."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Id1dV04fAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coverage_list = [1.0, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhwFKjjh4e-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "18ee0eab-16da-4547-80c1-5a7a58affc2a"
      },
      "source": [
        "for coverage in coverage_list:\n",
        "    sub_result = result[:int(len(result) * coverage)]\n",
        "    acc = sum([np.argmax(elem) for elem in sub_result[:, :-2]] == sub_result[:, -1])\n",
        "    print(f\"Coverage: {coverage:.2f}, Error: {(1.0 - acc / len(sub_result)) * 100:.2f}%\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coverage: 1.00, Error: 12.93%\n",
            "Coverage: 0.95, Error: 10.59%\n",
            "Coverage: 0.90, Error: 8.58%\n",
            "Coverage: 0.85, Error: 7.06%\n",
            "Coverage: 0.80, Error: 5.93%\n",
            "Coverage: 0.75, Error: 4.88%\n",
            "Coverage: 0.70, Error: 4.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohZN3hG46IEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeki1ZjoUa8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdG00cayUbAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBYZxf9N8mnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z4JUSJy4e8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbhqeTqE4gm6",
        "colab_type": "text"
      },
      "source": [
        "# Trial and Errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXFO1LWCoN6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9)\n",
        "vgg16 = VGGClassifier(num_classes=10 + 1)  # +1 is for abstention class\n",
        "\n",
        "test = tf.train.Checkpoint(optimizer=optimizer, model=vgg16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRauuoqOoPsg",
        "colab_type": "code",
        "outputId": "4aa15263-09ba-4860-d6b3-a5b6d6c880fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test.restore(\"./gdrive/My Drive/DeepGamblers/ckpt-4\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcb8004c080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xhJ2NY8objZ",
        "colab_type": "code",
        "outputId": "ca771896-bf9c-41fc-ceeb-ac72fa94b340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test.model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.VGGClassifier at 0x7fcb803cb0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9gVX-BpVJBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "42b6b0f0-5005-4953-8451-bbc00c04c398"
      },
      "source": [
        "test.optimizer.lr"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.000625>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHX7gyBiOIW",
        "colab_type": "code",
        "outputId": "f6467364-6f5e-4211-a117-624b09a9bd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "predictions, answers = evaluate(test.model, testset)\n",
        "print(sum([np.argmax(elem) for elem in predictions[:, :-1]] == answers) / len(predictions) )"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0wZS1yVokui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}